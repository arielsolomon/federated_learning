{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "MvQKalTzbtqR"
   },
   "outputs": [],
   "source": [
    "#!pip install -q flwr[simulation] torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /home/user1/.local/lib/python3.10/site-packages (1.13.1+cu117)\n",
      "Requirement already satisfied: typing-extensions in /home/user1/.local/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "ERROR: unknown command \"opencensus\"\n"
     ]
    }
   ],
   "source": [
    "#pip install ray\n",
    "!pip3 install torch\n",
    "!pip3 opencensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDiXoXzVbtqR"
   },
   "source": [
    "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "zzY27NIKbtqR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from simple_numpy_client.ipynb\n",
      "Training on cpu using PyTorch 1.13.1+cu117 and Flower 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "import sys\n",
    "sys.path.append('/home/user1/ariel/federated_learning/base_line_fed_single_client/')\n",
    "from load_dataset import load_datasets\n",
    "from load_model import Net\n",
    "from trainer import train, test\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "\n",
    "import argparse\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from simple_numpy_client import SimpleNumpyClient\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdjOqT2FbtqS"
   },
   "source": [
    "\n",
    "### Loading the data\n",
    "\n",
    "Federated learning can be applied to many different types of tasks across different domains. In this tutorial, we introduce federated learning by training a simple convolutional neural network (CNN) on the popular CIFAR-10 dataset. CIFAR-10 can be used to train image classifiers that distinguish between images from ten different classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "MITDWe9lbtqS"
   },
   "outputs": [],
   "source": [
    "CLASSES = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJw1X7bJbtqS"
   },
   "source": [
    "We simulate having multiple datasets from multiple organizations (also called the \"cross-silo\" setting in federated learning) by splitting the original CIFAR-10 dataset into multiple partitions. Each partition will represent the data from a single organization. We're doing this purely for experimentation purposes, in the real world there's no need for data splitting because each organization already has their own data (so the data is naturally partitioned).\n",
    "\n",
    "Each organization will act as a client in the federated learning system. So having ten organizations participate in a federation means having ten clients connected to the federated learning server:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "3y33S5oPbtqT"
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eiFOE1wbtqT"
   },
   "source": [
    "\n",
    "Let's now load the CIFAR-10 training and test set, partition them into ten smaller datasets (each split into training and validation set), and wrap the resulting partitions by creating a PyTorch `DataLoader` for each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "vr48gLfDbtqT"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR-4yxHkbtqT"
   },
   "source": [
    "We now have a list of ten training sets and ten validation sets (`trainloaders` and `valloaders`) representing the data of ten different organizations. Each `trainloader`/`valloader` pair contains 4500 training examples and 500 validation examples. There's also a single `testloader` (we did not split the test set). Again, this is only necessary for building research or educational systems, actual federated learning systems have their data naturally distributed across multiple partitions.\n",
    "\n",
    "Let's take a look at the first batch of images and labels in the first training set (i.e., `trainloaders[0]`) before we move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "PMynHFqLbtqT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset loaded\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "load dataset loaded\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ood = False\n",
    "trainloaders, valloaders, testloader = load_datasets(ood, NUM_CLIENTS,BATCH_SIZE)\n",
    "ood = True\n",
    "trainloaders_ood, valloaders_ood, testloader_ood = load_datasets(ood, NUM_CLIENTS,BATCH_SIZE)\n",
    "images, labels = next(iter(trainloaders[0]))\n",
    "\n",
    "# Reshape and convert images to a NumPy array\n",
    "# matplotlib requires images with the shape (height, width, 3)\n",
    "images = images.permute(0, 2, 3, 1).numpy()\n",
    "# Denormalize\n",
    "images = images / 2 + 0.5\n",
    "\n",
    "# Create a figure and a grid of subplots\n",
    "# fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
    "\n",
    "# # Loop over the images and plot them\n",
    "# for i, ax in enumerate(axs.flat):\n",
    "#     ax.imshow(images[i])\n",
    "#     ax.set_title(CLASSES[labels[i]])\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# # Show the plot\n",
    "# fig.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaPQmUSwbtqT"
   },
   "source": [
    "The output above shows a random batch of images from the first `trainloader` in our list of ten `trainloaders`. It also prints the labels associated with each image (i.e., one of the ten possible labels we've seen above). If you run the cell again, you should see another batch of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW4oJ3DibtqT"
   },
   "source": [
    "## Step 1: Centralized Training with PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ypQNC7IbtqT"
   },
   "source": [
    "Next, we're going to use PyTorch to define a simple convolutional neural network. This introduction assumes basic familiarity with PyTorch, so it doesn't cover the PyTorch-related aspects in full detail. If you want to dive deeper into PyTorch, we recommend [*DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ*](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nccx4451btqT"
   },
   "source": [
    "### Defining the model\n",
    "\n",
    "We use the simple CNN described in the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "FrdsU6uxbtqT"
   },
   "outputs": [],
   "source": [
    "net = Net().to(DEVICE)\n",
    "net1 = Net().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgvl6RR1btqU"
   },
   "source": [
    "Let's continue with the usual training and test functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niOASZihbtqU"
   },
   "source": [
    "### Training the model\n",
    "\n",
    "We now have all the basic building blocks we need: a dataset, a model, a training function, and a test function. Let's put them together to train the model on the dataset of one of our organizations (`trainloaders[0]`). This simulates the reality of most machine learning projects today: each organization has their own data and trains models only on this internal data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "M0dl_FYibtqU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: validation loss 0.04389884672164917, accuracy 0.4892\n",
      "Epoch 2: validation loss 0.04121264886856079, accuracy 0.5388\n",
      "Epoch 3: validation loss 0.038053874671459195, accuracy 0.5708\n",
      "Epoch 4: validation loss 0.037430974113941196, accuracy 0.569\n",
      "Epoch 5: validation loss 0.036095033943653106, accuracy 0.593\n",
      "Final test set performance:\n",
      "\tloss 0.03546343259215355\n",
      "\taccuracy 0.6047\n"
     ]
    }
   ],
   "source": [
    "trainloader = trainloaders[0]\n",
    "valloader = valloaders[0]\n",
    "testloader = testloader\n",
    "for epoch in range(5):\n",
    "    train(net, trainloader, 1)\n",
    "    loss, accuracy = test(net, valloader)\n",
    "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
    "\n",
    "loss, accuracy = test(net, testloader)\n",
    "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: validation loss 0.19291693868637086, accuracy 0.1272\n",
      "Epoch 2: validation loss 0.2146178647994995, accuracy 0.1858\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      5\u001b[0m     train(net1, trainloader, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: validation loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m test(net, testloader)\n",
      "File \u001b[0;32m<string>:34\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(net, testloader)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/cifar.py:115\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Image.py:3099\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtobytes\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3099\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3101\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloader = trainloaders_ood[0]\n",
    "valloader = valloaders_ood[0]\n",
    "testloader = testloader_ood\n",
    "for epoch in range(5):\n",
    "    train(net1, trainloader, 1)\n",
    "    loss, accuracy = test(net1, testloader)\n",
    "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
    "\n",
    "loss, accuracy = test(net, testloader)\n",
    "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8_rcGZGbtqU"
   },
   "source": [
    "Training the simple CNN on our CIFAR-10 split for 5 epochs should result in a test set accuracy of about 41%, which is not good, but at the same time, it doesn't really matter for the purposes of this tutorial. The intent was just to show a simplistic centralized training pipeline that sets the stage for what comes next - federated learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pP_9ZFs_btqU"
   },
   "source": [
    "## Step 2: Federated Learning with Flower\n",
    "\n",
    "Step 1 demonstrated a simple centralized training pipeline. All data was in one place (i.e., a single `trainloader` and a single `valloader`). Next, we'll simulate a situation where we have multiple datasets in multiple organizations and where we train a model over these organizations using federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlB6QW_NbtqU"
   },
   "source": [
    "### Updating model parameters\n",
    "\n",
    "In federated learning, the server sends the global model parameters to the client, and the client updates the local model with the parameters received from the server. It then trains the model on the local data (which changes the model parameters locally) and sends the updated/changed model parameters back to the server (or, alternatively, it sends just the gradients back to the server, not the full model parameters).\n",
    "\n",
    "We need two helper functions to update the local model with parameters received from the server and to get the updated model parameters from the local model: `set_parameters` and `get_parameters`. The following two functions do just that for the PyTorch model above.\n",
    "\n",
    "The details of how this works are not really important here (feel free to consult the PyTorch documentation if you want to learn more). In essence, we use `state_dict` to access PyTorch model parameter tensors. The parameter tensors are then converted to/from a list of NumPy ndarray's (which Flower knows how to serialize/deserialize):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71u7EJrjbtqU"
   },
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNwaL9m7btqU"
   },
   "source": [
    "### Implementing a Flower client\n",
    "\n",
    "With that out of the way, let's move on to the interesting part. Federated learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement and requires us to write less boilerplate.\n",
    "\n",
    "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`:\n",
    "\n",
    "* `get_parameters`: Return the current local model parameters\n",
    "* `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server\n",
    "* `evaluate`: Receive model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
    "\n",
    "We mentioned that our clients will use the previously defined PyTorch components for model training and evaluation. Let's see a simple Flower client implementation that brings everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDi_U84VbtqU"
   },
   "outputs": [],
   "source": [
    "# class FlowerClient(fl.client.NumPyClient):\n",
    "#     def __init__(self, net, trainloader, valloader):\n",
    "#         self.net = net\n",
    "#         self.trainloader = trainloader\n",
    "#         self.valloader = valloader\n",
    "\n",
    "#     def get_parameters(self, config):\n",
    "#         return get_parameters(self.net)\n",
    "\n",
    "#     def fit(self, parameters, config):\n",
    "#         set_parameters(self.net, parameters)\n",
    "#         train(self.net, self.trainloader, epochs=1)\n",
    "#         return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "#     def evaluate(self, parameters, config):\n",
    "#         set_parameters(self.net, parameters)\n",
    "#         loss, accuracy = test(self.net, self.valloader)\n",
    "#         return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client(net, train_fn, test_fn, trainloader, testloader):\n",
    "    return SimpleNumpyClient(net=net, train_fn=train_fn, test_fn=test_fn, trainloader=trainloader,\n",
    "                             testloader=testloader)\n",
    "\n",
    "\n",
    "def start_client(client):\n",
    "    print('start_client')\n",
    "    fl.client.start_numpy_client(server_address=\"[::]:8080\", client=client)\n",
    "    print('after start client')\n",
    "\n",
    "\n",
    "def start_server():\n",
    "    print('start_server')\n",
    "    fl.server.start_server(config=fl.server.ServerConfig(num_rounds=20))\n",
    "    print('after start server')\n",
    "\n",
    "\n",
    "def start_node(arg):\n",
    "    if isinstance(arg, SimpleNumpyClient):\n",
    "        print('Sleep ...')\n",
    "        sleep(1)\n",
    "        print('Launch Client')\n",
    "        start_client(arg)\n",
    "        print('Exit Client')\n",
    "    else:\n",
    "        print('Launch Server')\n",
    "        start_server()\n",
    "        print('Exit Server')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQzQQI5ibtqU"
   },
   "source": [
    "Our class `FlowerClient` defines how local training/evaluation will be performed and allows Flower to call the local training/evaluation through `fit` and `evaluate`. Each instance of `FlowerClient` represents a *single client* in our federated learning system. Federated learning systems have multiple clients (otherwise, there's not much to federate), so each client will be represented by its own instance of `FlowerClient`. If we have, for example, three clients in our workload, then we'd have three instances of `FlowerClient`. Flower calls `FlowerClient.fit` on the respective instance when the server selects a particular client for training (and `FlowerClient.evaluate` for evaluation).\n",
    "\n",
    "### Using the Virtual Client Engine\n",
    "\n",
    "In this notebook, we want to simulate a federated learning system with 10 clients on a single machine. This means that the server and all 10 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 10 clients would mean having 10 instances of `FlowerClient` in memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning.\n",
    "\n",
    "In addition to the regular capabilities where server and clients run on multiple machines, Flower, therefore, provides special simulation capabilities that create `FlowerClient` instances only when they are actually necessary for training or evaluation. To enable the Flower framework to create clients when necessary, we need to implement a function called `client_fn` that creates a `FlowerClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use, so they should not keep any local state). Clients are identified by a client ID, or short `cid`. The `cid` can be used, for example, to load different local data partitions for different clients, as can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6z_FwtjbtqV"
   },
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    net = Net().to(DEVICE)\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return FlowerClient(net, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "og32-cspbtqV"
   },
   "source": [
    "### Starting the training\n",
    "\n",
    "We now have the class `FlowerClient` which defines client-side training/evaluation and `client_fn` which allows Flower to create `FlowerClient` instances whenever it needs to call `fit` or `evaluate` on one particular client. The last step is to start the actual simulation using `flwr.simulation.start_simulation`.\n",
    "\n",
    "The function `start_simulation` accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate (`num_clients`), the number of federated learning rounds (`num_rounds`), and the strategy. The strategy encapsulates the federated learning approach/algorithm, for example, *Federated Averaging* (FedAvg).\n",
    "\n",
    "Flower has a number of built-in strategies, but we can also use our own strategy implementations to customize nearly all aspects of the federated learning approach. For this example, we use the built-in `FedAvg` implementation and customize it using a few basic parameters. The last step is the actual call to `start_simulation` which - you guessed it - starts the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "4VVSxkTybtqV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-09-26 14:16:07,811 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
      "2023-09-26 14:16:10,818\tERROR services.py:1222 -- Failed to start the dashboard , return code 1\n",
      "2023-09-26 14:16:10,821\tERROR services.py:1247 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2023-09-26 14:16:10,823\tERROR services.py:1291 -- \n",
      "The last 20 lines of /tmp/ray/session_2023-09-26_14-16-09_194956_390313/logs/dashboard.log (it contains the error message from the dashboard): \n",
      "  File \"/home/user1/.local/lib/python3.10/site-packages/ray/dashboard/head.py\", line 325, in run\n",
      "    modules = self._load_modules(self._modules_to_load)\n",
      "  File \"/home/user1/.local/lib/python3.10/site-packages/ray/dashboard/head.py\", line 219, in _load_modules\n",
      "    head_cls_list = dashboard_utils.get_all_modules(DashboardHeadModule)\n",
      "  File \"/home/user1/.local/lib/python3.10/site-packages/ray/dashboard/utils.py\", line 134, in get_all_modules\n",
      "    raise e\n",
      "  File \"/home/user1/.local/lib/python3.10/site-packages/ray/dashboard/utils.py\", line 121, in get_all_modules\n",
      "    importlib.import_module(name)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/user1/.local/lib/python3.10/site-packages/ray/dashboard/modules/reporter/reporter_agent.py\", line 26, in <module>\n",
      "    from opencensus.stats import stats as stats_module\n",
      "ModuleNotFoundError: No module named 'opencensus.stats'\n",
      "2023-09-26 14:16:11,181\tINFO worker.py:1642 -- Started a local Ray instance.\n",
      "INFO flwr 2023-09-26 14:16:11,907 | app.py:180 | Flower VCE: Ray initialized with resources: {'object_store_memory': 5454202060.0, 'memory': 10908404123.0, 'CPU': 16.0, 'node:__internal_head__': 1.0, 'accelerator_type:G': 1.0, 'GPU': 1.0, 'node:172.16.17.3': 1.0}\n",
      "INFO:flwr:Flower VCE: Ray initialized with resources: {'object_store_memory': 5454202060.0, 'memory': 10908404123.0, 'CPU': 16.0, 'node:__internal_head__': 1.0, 'accelerator_type:G': 1.0, 'GPU': 1.0, 'node:172.16.17.3': 1.0}\n",
      "INFO flwr 2023-09-26 14:16:11,908 | server.py:86 | Initializing global parameters\n",
      "INFO:flwr:Initializing global parameters\n",
      "INFO flwr 2023-09-26 14:16:11,908 | server.py:273 | Requesting initial parameters from one random client\n",
      "INFO:flwr:Requesting initial parameters from one random client\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-09-26 14:16:11,991 E 393005 393042] (raylet) agent_manager.cc:70: The raylet exited immediately because one Ray agent failed, agent_name = dashboard_agent/424238335.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m The raylet fate shares with the agent. This can happen because\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m - The version of `grpcio` doesn't follow Ray's requirement. Agent can segfault with the incorrect `grpcio` version. Check the grpcio version `pip freeze | grep grpcio`.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m - The agent failed to start because of unexpected error or port conflict. Read the log `cat /tmp/ray/session_latest/logs/{dashboard_agent|runtime_env_agent}.log`. You can find the log file structure here https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m - The agent is killed by the OS (e.g., out of memory).\n"
     ]
    },
    {
     "ename": "RaySystemError",
     "evalue": "System error: Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRaySystemError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     client_resources \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Start simulation\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/app.py:197\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001b[0m\n\u001b[1;32m    194\u001b[0m     initialized_server\u001b[38;5;241m.\u001b[39mclient_manager()\u001b[38;5;241m.\u001b[39mregister(client\u001b[38;5;241m=\u001b[39mclient_proxy)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43m_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m event(EventType\u001b[38;5;241m.\u001b[39mSTART_SIMULATION_LEAVE)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hist\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/server/app.py:217\u001b[0m, in \u001b[0;36m_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fl\u001b[39m(\n\u001b[1;32m    213\u001b[0m     server: Server,\n\u001b[1;32m    214\u001b[0m     config: ServerConfig,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m History:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp_fit: losses_distributed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(hist\u001b[38;5;241m.\u001b[39mlosses_distributed))\n\u001b[1;32m    219\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapp_fit: metrics_distributed_fit \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(hist\u001b[38;5;241m.\u001b[39mmetrics_distributed_fit))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/server/server.py:87\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Initialize parameters\u001b[39;00m\n\u001b[1;32m     86\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing global parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_initial_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating initial parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;241m0\u001b[39m, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/server/server.py:276\u001b[0m, in \u001b[0;36mServer._get_initial_parameters\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    274\u001b[0m random_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_manager\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    275\u001b[0m ins \u001b[38;5;241m=\u001b[39m GetParametersIns(config\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m--> 276\u001b[0m get_parameters_res \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived initial parameters from one random client\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_parameters_res\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:68\u001b[0m, in \u001b[0;36mRayClientProxy.get_parameters\u001b[0;34m(self, ins, timeout)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_parameters\u001b[39m(\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m, ins: common\u001b[38;5;241m.\u001b[39mGetParametersIns, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m]\n\u001b[1;32m     64\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m common\u001b[38;5;241m.\u001b[39mGetParametersRes:\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the current local model parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     future_paramseters_res \u001b[38;5;241m=\u001b[39m \u001b[43mlaunch_and_get_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         res \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mget(future_paramseters_res, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/remote_function.py:241\u001b[0m, in \u001b[0;36mRemoteFunction.options.<locals>.FuncWrapper.remote\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremote\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mupdated_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     23\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py:310\u001b[0m, in \u001b[0;36m_tracing_task_invocation.<locals>._invocation_remote_span\u001b[0;34m(self, args, kwargs, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[1;32m    313\u001b[0m tracer \u001b[38;5;241m=\u001b[39m _opentelemetry\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mget_tracer(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/remote_function.py:442\u001b[0m, in \u001b[0;36mRemoteFunction._remote\u001b[0;34m(self, args, kwargs, **task_options)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    440\u001b[0m     invocation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorator(invocation)\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minvocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ray/remote_function.py:411\u001b[0m, in \u001b[0;36mRemoteFunction._remote.<locals>.invocation\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m worker\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m ray\u001b[38;5;241m.\u001b[39m_private\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39mLOCAL_MODE:\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_cross_language\n\u001b[1;32m    410\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross language remote function cannot be executed locally.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 411\u001b[0m object_refs \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_language\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_descriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlist_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_exception_allowlist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduling_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugger_breakpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_runtime_env_info\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# Reset worker's debug context from the last \"remote\" command\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# (which applies only to this .remote call).\u001b[39;00m\n\u001b[1;32m    427\u001b[0m worker\u001b[38;5;241m.\u001b[39mdebugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3518\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.submit_task\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3522\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.submit_task\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:694\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_and_increment_put_refs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:685\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_and_increment_put_refs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:779\u001b[0m, in \u001b[0;36mray._raylet.prepare_args_internal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3260\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.put_serialized_object_and_increment_local_ref\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3152\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker._create_put_buffer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:457\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRaySystemError\u001b[0m: System error: Broken pipe"
     ]
    }
   ],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=1,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=1,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=1,  # Wait until all 10 clients are available\n",
    ")\n",
    "\n",
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = None\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwGItOzYbtqV"
   },
   "source": [
    "### Behind the scenes\n",
    "\n",
    "So how does this work? How does Flower execute this simulation?\n",
    "\n",
    "When we call `start_simulation`, we tell Flower that there are 10 clients (`num_clients=10`). Flower then goes ahead an asks the `FedAvg` strategy to select clients. `FedAvg` knows that it should select 100% of the available clients (`fraction_fit=1.0`), so it goes ahead and selects 10 random clients (i.e., 100% of 10).\n",
    "\n",
    "Flower then asks the selected 10 clients to train the model. When the server receives the model parameter updates from the clients, it hands those updates over to the strategy (*FedAvg*) for aggregation. The strategy aggregates those updates and returns the new global model, which then gets used in the next round of federated learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPvN4KyubtqV"
   },
   "source": [
    "### Where's the accuracy?\n",
    "\n",
    "You may have noticed that all metrics except for `losses_distributed` are empty. Where did the `{\"accuracy\": float(accuracy)}` go?\n",
    "\n",
    "Flower can automatically aggregate losses returned by individual clients, but it cannot do the same for metrics in the generic metrics dictionary (the one with the `accuracy` key). Metrics dictionaries can contain very different kinds of metrics and even key/value pairs that are not metrics at all, so the framework does not (and can not) know how to handle these automatically.\n",
    "\n",
    "As users, we need to tell the framework how to handle/aggregate these custom metrics, and we do so by passing metric aggregation functions to the strategy. The strategy will then call these functions whenever it receives fit or evaluate metrics from clients. The two possible functions are `fit_metrics_aggregation_fn` and `evaluate_metrics_aggregation_fn`.\n",
    "\n",
    "Let's create a simple weighted averaging function to aggregate the `accuracy` metric we return from `evaluate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQazTovWbtqV"
   },
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTt8LgKTbtqV"
   },
   "source": [
    "The only thing left to do is to tell the strategy to call this function whenever it receives evaluation metric dictionaries from the clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XewjALjDbtqV"
   },
   "outputs": [],
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=0.5,\n",
    "    min_fit_clients=10,\n",
    "    min_evaluate_clients=5,\n",
    "    min_available_clients=10,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=5),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaJK4O1-btqY"
   },
   "source": [
    "We now have a full system that performs federated training and federated evaluation. It uses the `weighted_average` function to aggregate custom evaluation metrics and calculates a single `accuracy` metric across all clients on the server side.\n",
    "\n",
    "The other two categories of metrics (`losses_centralized` and `metrics_centralized`) are still empty because they only apply when centralized evaluation is being used. Part two of the Flower tutorial will cover centralized evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbcrO5q6btqY"
   },
   "source": [
    "## Final remarks\n",
    "\n",
    "Congratulations, you just trained a convolutional neural network, federated over 10 clients! With that, you understand the basics of federated learning with Flower. The same approach you've seen can be used with other machine learning frameworks (not just PyTorch) and tasks (not just CIFAR-10 images classification), for example NLP with Hugging Face Transformers or speech with SpeechBrain.\n",
    "\n",
    "In the next notebook, we're going to cover some more advanced concepts. Want to customize your strategy? Initialize parameters on the server side? Or evaluate the aggregated model on the server side? We'll cover all this and more in the next tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4GR7-qDbtqY"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "Before you continue, make sure to join the Flower community on Slack: [Join Slack](https://flower.dev/join-slack/)\n",
    "\n",
    "There's a dedicated `#questions` channel if you need help, but we'd also love to hear who you are in `#introductions`!\n",
    "\n",
    "The [Flower Federated Learning Tutorial - Part 2](https://flower.dev/docs/framework/tutorial-use-a-federated-learning-strategy-pytorch.html) goes into more depth about strategies and all the advanced things you can build with them."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flower-1-Intro-to-FL-PyTorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
