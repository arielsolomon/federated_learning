{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MvQKalTzbtqR"
   },
   "outputs": [],
   "source": [
    "#!pip install -q flwr[simulation] torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /home/user1/.local/lib/python3.10/site-packages (1.13.1+cu117)\n",
      "Requirement already satisfied: typing-extensions in /home/user1/.local/lib/python3.10/site-packages (from torch) (4.7.1)\n"
     ]
    }
   ],
   "source": [
    "#pip install ray\n",
    "!pip3 install torch\n",
    "#!pip3 opencensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDiXoXzVbtqR"
   },
   "source": [
    "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zzY27NIKbtqR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from load_dataset.ipynb\n",
      "\n",
      "load dataset loaded\n",
      "importing Jupyter notebook from load_model.ipynb\n",
      "\n",
      "Model loaded\n",
      "importing Jupyter notebook from trainer.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 16:40:38.786892: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-26 16:40:38.816099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 16:40:39.266482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from simple_numpy_client.ipynb\n",
      "Training on cpu using PyTorch 1.13.1+cu117 and Flower 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "import sys\n",
    "sys.path.append('/home/user1/ariel/federated_learning/base_line_fed_single_client/')\n",
    "from load_dataset import load_datasets\n",
    "from load_model import Net\n",
    "from trainer import train, test\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "\n",
    "import argparse\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from simple_numpy_client import SimpleNumpyClient\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdjOqT2FbtqS"
   },
   "source": [
    "\n",
    "### Loading the data\n",
    "\n",
    "Federated learning can be applied to many different types of tasks across different domains. In this tutorial, we introduce federated learning by training a simple convolutional neural network (CNN) on the popular CIFAR-10 dataset. CIFAR-10 can be used to train image classifiers that distinguish between images from ten different classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MITDWe9lbtqS"
   },
   "outputs": [],
   "source": [
    "CLASSES = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJw1X7bJbtqS"
   },
   "source": [
    "We simulate having multiple datasets from multiple organizations (also called the \"cross-silo\" setting in federated learning) by splitting the original CIFAR-10 dataset into multiple partitions. Each partition will represent the data from a single organization. We're doing this purely for experimentation purposes, in the real world there's no need for data splitting because each organization already has their own data (so the data is naturally partitioned).\n",
    "\n",
    "Each organization will act as a client in the federated learning system. So having ten organizations participate in a federation means having ten clients connected to the federated learning server:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3y33S5oPbtqT"
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eiFOE1wbtqT"
   },
   "source": [
    "\n",
    "Let's now load the CIFAR-10 training and test set, partition them into ten smaller datasets (each split into training and validation set), and wrap the resulting partitions by creating a PyTorch `DataLoader` for each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vr48gLfDbtqT"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR-4yxHkbtqT"
   },
   "source": [
    "We now have a list of ten training sets and ten validation sets (`trainloaders` and `valloaders`) representing the data of ten different organizations. Each `trainloader`/`valloader` pair contains 4500 training examples and 500 validation examples. There's also a single `testloader` (we did not split the test set). Again, this is only necessary for building research or educational systems, actual federated learning systems have their data naturally distributed across multiple partitions.\n",
    "\n",
    "Let's take a look at the first batch of images and labels in the first training set (i.e., `trainloaders[0]`) before we move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PMynHFqLbtqT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset loaded\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "load dataset loaded\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ood = False\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS,BATCH_SIZE,ood)\n",
    "ood = True\n",
    "trainloaders_ood, valloaders_ood, testloader_ood = load_datasets(NUM_CLIENTS,BATCH_SIZE,ood)\n",
    "images, labels = next(iter(trainloaders[0]))\n",
    "\n",
    "# Reshape and convert images to a NumPy array\n",
    "# matplotlib requires images with the shape (height, width, 3)\n",
    "images = images.permute(0, 2, 3, 1).numpy()\n",
    "# Denormalize\n",
    "images = images / 2 + 0.5\n",
    "\n",
    "# Create a figure and a grid of subplots\n",
    "# fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
    "\n",
    "# # Loop over the images and plot them\n",
    "# for i, ax in enumerate(axs.flat):\n",
    "#     ax.imshow(images[i])\n",
    "#     ax.set_title(CLASSES[labels[i]])\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# # Show the plot\n",
    "# fig.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaPQmUSwbtqT"
   },
   "source": [
    "The output above shows a random batch of images from the first `trainloader` in our list of ten `trainloaders`. It also prints the labels associated with each image (i.e., one of the ten possible labels we've seen above). If you run the cell again, you should see another batch of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW4oJ3DibtqT"
   },
   "source": [
    "## Step 1: Centralized Training with PyTorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ypQNC7IbtqT"
   },
   "source": [
    "Next, we're going to use PyTorch to define a simple convolutional neural network. This introduction assumes basic familiarity with PyTorch, so it doesn't cover the PyTorch-related aspects in full detail. If you want to dive deeper into PyTorch, we recommend [*DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ*](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nccx4451btqT"
   },
   "source": [
    "### Defining the model\n",
    "\n",
    "We use the simple CNN described in the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FrdsU6uxbtqT"
   },
   "outputs": [],
   "source": [
    "net = Net().to(DEVICE)\n",
    "net1 = Net().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgvl6RR1btqU"
   },
   "source": [
    "Let's continue with the usual training and test functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niOASZihbtqU"
   },
   "source": [
    "### Training the model\n",
    "\n",
    "We now have all the basic building blocks we need: a dataset, a model, a training function, and a test function. Let's put them together to train the model on the dataset of one of our organizations (`trainloaders[0]`). This simulates the reality of most machine learning projects today: each organization has their own data and trains models only on this internal data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "M0dl_FYibtqU"
   },
   "outputs": [],
   "source": [
    "def trainer1(trainloaders, valloaders, testloader, net):\n",
    "    net = net\n",
    "    trainloader = trainloaders[0]\n",
    "    valloader = valloaders[0]\n",
    "    testloader = testloader\n",
    "    for epoch in range(5):\n",
    "        train(net, trainloader, 1)\n",
    "        loss, accuracy = test(net, valloaders)\n",
    "        print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
    "    \n",
    "    loss, accuracy = test(net, testloader)\n",
    "    print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer1(trainloaders, valloaders, testloader, net)\n",
    "# trainloader = trainloaders_ood[0]\n",
    "# valloader = valloaders_ood[0]\n",
    "# testloader = testloader_ood\n",
    "# for epoch in range(5):\n",
    "#     train(net1, trainloader, 1)\n",
    "#     loss, accuracy = test(net1, testloader)\n",
    "#     print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
    "\n",
    "# loss, accuracy = test(net, testloader)\n",
    "# print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client(net, train_fn, test_fn, trainloader, testloader):\n",
    "    return SimpleNumpyClient(net=net, train_fn=train_fn, test_fn=test_fn, trainloader=trainloader,\n",
    "                             testloader=testloader)\n",
    "\n",
    "\n",
    "def start_client(client):\n",
    "    print('start_client')\n",
    "    fl.client.start_numpy_client(server_address=\"[::]:8080\", client=client)\n",
    "    print('after start client')\n",
    "\n",
    "\n",
    "def start_server():\n",
    "    print('start_server')\n",
    "    fl.server.start_server(config=fl.server.ServerConfig(num_rounds=20))\n",
    "    print('after start server')\n",
    "\n",
    "\n",
    "def start_node(arg):\n",
    "    if isinstance(arg, SimpleNumpyClient):\n",
    "        print('Sleep ...')\n",
    "        sleep(1)\n",
    "        print('Launch Client')\n",
    "        start_client(arg)\n",
    "        print('Exit Client')\n",
    "    else:\n",
    "        print('Launch Server')\n",
    "        start_server()\n",
    "        print('Exit Server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Freezing suceed\n",
      "\n",
      "load dataset loaded\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "load dataset loaded\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "SimpleNumpyClient.__init__ 1\n",
      "SimpleNumpyClient.__init__ 2\n",
      "Launch Server\n",
      "start_server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-09-26 16:44:12,912 | server.py:273 | Requesting initial parameters from one random client\n",
      "INFO flwr 2023-09-26 16:44:12,900 | app.py:148 | Starting Flower server, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
      "INFO flwr 2023-09-26 16:44:12,911 | app.py:168 | Flower ECE: gRPC server running (20 rounds), SSL is disabled\n",
      "INFO flwr 2023-09-26 16:44:12,912 | server.py:86 | Initializing global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep ...\n",
      "Sleep ...\n",
      "Launch Client\n",
      "start_client\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-09-26 16:44:15,553 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-09-26 16:44:15,555 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-09-26 16:44:15,556 | connection.py:39 | ChannelConnectivity.CONNECTING\n",
      "DEBUG flwr 2023-09-26 16:44:15,556 | connection.py:39 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************\n",
      "SimpleNumpyClient.get_parameters id 1 config {}\n",
      "******************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-09-26 16:44:15,563 | server.py:277 | Received initial parameters from one random client\n",
      "INFO flwr 2023-09-26 16:44:15,564 | server.py:88 | Evaluating initial parameters\n",
      "INFO flwr 2023-09-26 16:44:15,564 | server.py:101 | FL starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch Client\n",
      "start_client\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-09-26 16:44:15,692 | grpc.py:50 | Opened insecure gRPC connection (no certificates were passed)\n",
      "DEBUG flwr 2023-09-26 16:44:15,695 | connection.py:39 | ChannelConnectivity.IDLE\n",
      "DEBUG flwr 2023-09-26 16:44:15,697 | server.py:218 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
      "DEBUG flwr 2023-09-26 16:44:15,697 | connection.py:39 | ChannelConnectivity.READY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************************************************************************************\n",
      "\n",
      "SimpleNumpyClient.fit SimpleNumpyClient.fit1 \n",
      "2\n",
      "\n",
      "******************************************\n",
      "\n",
      "SimpleNumpyClient.set_parameters id 1 parameters num 10******************************************\n",
      "\n",
      "******************************************SimpleNumpyClient.set_parameters id 2 parameters num 10\n",
      "\n",
      "******************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2023-09-26 16:44:15,737 | server.py:232 | fit_round 1 received 0 results and 2 failures\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # parser = argparse.ArgumentParser(description=\"Private Federated Learning Flower\")\n",
    "\n",
    "    # parser.add_argument(\"--data-path\", type=str, default=\"~/datasets/cifar\", help=\"dir path for datafolder\")\n",
    "    # parser.add_argument(\"--num-clients\", type=int, default=\"1\", help=\"Number of clients in federation\")\n",
    "    # parser.add_argument(\"--batch-size\", type=int, default=\"128\", help=\"Number of images in train batch\")\n",
    "    # parser.add_argument(\"--node-type\", type=str, choices=['client', 'server'], default='client',\n",
    "    #                     help='client node or server node')\n",
    "    # parser.add_argument(\"--ood\", type=bool, default=False, help='client node or server node')\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    net = Net().to(DEVICE)\n",
    "    net1 = Net().to(DEVICE)\n",
    "    net_freez = net\n",
    "    net_freez1 = net1\n",
    "    #freez all\n",
    "    for param in net_freez.parameters():\n",
    "        param.requires_grad = False\n",
    "    # unfreez last layer:\n",
    "    # Unfreeze last layer\n",
    "    for param in net_freez.fc3.parameters():\n",
    "        param.requires_grad = True\n",
    "    print('\\nFreezing suceed')\n",
    "    trainloader, _, testloader = load_datasets(1,BATCH_SIZE,ood=False)\n",
    "    trainloader_ood, _, testloader_ood = load_datasets(1,BATCH_SIZE,ood=True)\n",
    "\n",
    "    clients = [get_client(net=net, train_fn=train, test_fn=test, trainloader=trainloader, testloader=testloader)\n",
    "               for _ in range(NUM_CLIENTS)]\n",
    "    client_ood = get_client(net=net1, train_fn=train, test_fn=test, trainloader=trainloader, testloader=testloader_ood)\n",
    "\n",
    "    nodes = [1] + clients + [client_ood]\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(start_node, nodes)\n",
    "\n",
    "    print()\n",
    "    print('******************')\n",
    "    print('Few shot training')\n",
    "    print('******************')\n",
    "    parameters = client_ood.get_parameters(config={})\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    print()\n",
    "    print('Verify weights')\n",
    "    loss, acc = test(net=net, testloader=testloader)\n",
    "    loss_ood, acc_ood = test(net=net, testloader=testloader_ood)\n",
    "    losses_on_original, accs_on_original, losses_on_aug, accs_on_aug = [loss_ood], [acc], [loss_ood], [acc_ood]\n",
    "    print(f'Retrain')\n",
    "    for i in tqdm(range(len(trainloader_ood))):\n",
    "        # num_few_shots = (i+1) * args.batch_size\n",
    "        # print(f'train using {num_few_shots} images. ({i+1} batches of {args.batch_size})')\n",
    "        train(net=net, trainloader=trainloader_ood, epochs=1, iterations=1)\n",
    "        # print('Original test set. Expect degraded acc')\n",
    "        loss, acc = test(net=net, testloader=testloader)\n",
    "        losses_on_original.append(loss)\n",
    "        accs_on_original.append(acc)\n",
    "        # print('OOD test set. Expect better acc than earlier')\n",
    "        loss, acc = test(net=net, testloader=testloader_ood)\n",
    "        losses_on_aug.append(loss)\n",
    "        accs_on_aug.append(acc)\n",
    "        with open('accs_on_aug.npy', 'wb') as f:\n",
    "            np.save(f, np.array(accs_on_aug))\n",
    "        with open('losses_on_aug.npy', 'wb') as f:\n",
    "            np.save(f, np.array(losses_on_aug))\n",
    "        with open('accs_on_original.npy', 'wb') as f:\n",
    "            np.save(f, np.array(accs_on_original))\n",
    "        with open('losses_on_original.npy', 'wb') as f:\n",
    "            np.save(f, np.array(losses_on_original))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flower-1-Intro-to-FL-PyTorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
