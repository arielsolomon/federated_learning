{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4557f9f-f65d-44c3-bb5b-61485884d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "load dataset loaded\n"
     ]
    }
   ],
   "source": [
    "print('\\nload dataset loaded')\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "def load_datasets(ood, NUM_CLIENTS,BATCH_SIZE):\n",
    "    print('\\nload dataset loaded')\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    if not ood:\n",
    "        testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "    else:\n",
    "        transform_ood = transforms.Compose([transforms.ToTensor(), transforms.Normalize((1.0, 0.25, 0.1),(0.5, 0.5, 0.5))])\n",
    "        testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform_ood)\n",
    "\n",
    "    # Split training set into 10 partitions to simulate the individual dataset\n",
    "    partition_size = len(trainset) // NUM_CLIENTS\n",
    "    lengths = [partition_size] * NUM_CLIENTS\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    return trainloaders, valloaders, testloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
